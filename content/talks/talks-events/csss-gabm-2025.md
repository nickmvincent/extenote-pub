---
type: talk
title: "A Data Flow Perspective on 'AI Social Simulation': Will Recent AI Advances Enable New Social Science, Destroy Ecosystems for Knowledge, or Something More Subdued?"
slug: csss-gabm-2025
date: 2025-10-01
event: CSSS Generative Agent-Based Models Workshop
slides_url: https://github.com/nickmvincent/public-talks/blob/main/2025-10_csss_gabm/talk-as-marp.pdf
abstract: >
  This talk examines AI social simulation through a data flow lens, exploring whether
  recent AI advances will enable new social science discoveries, threaten knowledge
  ecosystems, or produce more subdued outcomes. It covers AI's data dependence,
  problems with current LLM social simulation, and the STIE framework for mechanism
  plausibility.
tags:
  - ai-simulation
  - social-science
  - data-transparency
  - llm
visibility: public
---

# A Data Flow Perspective on AI Social Simulation

**Event:** CSSS Generative Agent-Based Models Workshop
**Date:** October 2025

## Abstract

This talk examines AI social simulation through a data flow lens, exploring whether recent AI advances will enable new social science discoveries, threaten knowledge ecosystems, or produce more subdued outcomes.

## Key Topics

### 1. AI's Data Dependence
How training data collectively shapes model behavior through the pipeline of collection, curation, training, and inference.

### 2. Problems with Current LLM Social Simulation
- Inability to trace mechanisms
- Reliance on closed APIs
- Reproducibility threats
- Non-determinism issues

### 3. Data Transparency & Leverage
Advocating for transparency in dataset selection to understand which communities influenced models.

### 4. Content Ecosystem Risks
The potential feedback loop where AI substitutes for platforms like Wikipedia, reducing volunteer contributions.

### 5. The STIE Framework
A scale for measuring mechanism plausibility in simulations:
- **S**imulation
- **T**arget
- **I**ntent
- **E**vidence

## Key Arguments

- AI's impact will fall between extremes: neither revolutionary discovery nor complete automation/destruction, but something "more subdued"
- Social scientists should advocate for training data transparency on epistemic grounds
- Current simulation work proves LLMs *can* produce phenomena but struggles to explain *how* or validate mechanisms
- Three paths forward: convincing tech companies, regulators, and supporting public AI development

## Materials

- [Slides (PDF)](https://github.com/nickmvincent/public-talks/blob/main/2025-10_csss_gabm/talk-as-marp.pdf)
- [Slides (HTML)](https://github.com/nickmvincent/public-talks/blob/main/2025-10_csss_gabm/talk-as-marp.html)
- [Semantic Scholar Collection](https://www.semanticscholar.org/) (papers mentioned in talk)

## Contact

- Website: [nickmvincent.com](https://nickmvincent.com)
- Newsletter: [Data Leverage](https://dataleverage.substack.com)
- Social: @nickmvincent on Bluesky, hci.social, Twitter
