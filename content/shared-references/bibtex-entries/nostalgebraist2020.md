---
type: bibtex_entry
citation_key: nostalgebraist2020
entry_type: misc
title: 'interpreting GPT: the logit lens'
authors:
  - nostalgebraist
year: '2020'
venue: LessWrong
url: >-
  https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens
visibility: public
check_log:
  checked_at: '2025-12-30T15:40:39.225Z'
  checked_with: auto
  status: not_found
manually_verified:
  verified_at: '2024-12-28T12:00:00.000Z'
  verified_by: agent
  notes: >-
    Verified against LessWrong. Published August 31, 2020 on AI Alignment Forum.
    Influential interpretability work.
canonical_source:
  url: >-
    https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens
  title: 'interpreting GPT: the logit lens'
  accessed_at: '2024-12-28'
  match_confidence: 1
tags:
  - ml-methods
  - language-models
  - interpretability
cited_in:
  - ranking-book
---

