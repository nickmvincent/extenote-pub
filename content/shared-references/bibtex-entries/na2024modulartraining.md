---
citation_key: na2024modulartraining
type: bibtex_entry
entry_type: inproceedings
title: >-
  Scalable Data Ablation Approximations for Language Models through Modular
  Training and Merging
authors:
  - Clara Na
  - Ian Magnusson
  - Ananya Harsh Jha
  - Tom Sherborne
  - Emma Strubell
  - Jesse Dodge
  - Pradeep Dasigi
year: '2024'
venue: EMNLP
url: 'https://arxiv.org/abs/2410.15661'
booktitle: EMNLP
visibility: public
check_log:
  checked_at: '2025-12-30T15:40:27.605Z'
  checked_with: 'auto:openalex'
  status: mismatch
  paper_id: 'https://openalex.org/W4404781955'
  fields:
    title:
      local: >-
        Scalable Data Ablation Approximations for Language Models through
        Modular Training and Merging
      remote: >-
        Scalable Data Ablation Approximations for Language Models through
        Modular Training and Merging
      match: true
    year:
      local: '2024'
      remote: '2024'
      match: true
    venue:
      local: EMNLP
      remote: null
      match: true
    doi:
      local: null
      remote: 10.18653/v1/2024.emnlp-main.1176
      match: true
    authors:
      local_count: 1
      remote_count: 7
      count_match: false
      details:
        - index: 0
          local: >-
            Na, Clara and Magnusson, Ian and Jha, Ananya Harsh and Sherborne,
            Tom and Strubell, Emma and Dodge, Jesse and Dasigi, Pradeep
          remote: Clara Na
          first_match: false
          last_match: true
  remote:
    title: >-
      Scalable Data Ablation Approximations for Language Models through Modular
      Training and Merging
    authors:
      - Clara Na
      - Ian Magnusson
      - Ananya Harsh Jha
      - Tom Sherborne
      - Emma Strubell
      - Jesse Dodge
      - Pradeep Dasigi
    year: 2024
    doi: 10.18653/v1/2024.emnlp-main.1176
tags:
  - ml-methods
  - language-models
cited_in:
  - data-leverage-blogs
  - personal-website
---

