---
type: bibtex_entry
citation_key: liu2023trustworthy
entry_type: article
title: >-
  Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models'
  Alignment
authors:
  - Yang Liu
  - Yuanshun Yao
  - Jean-Francois Ton
  - Xiaoying Zhang
  - Ruocheng Guo
  - Hao Cheng
  - Yegor Klochkov
  - Muhammad Faaiz Taufiq
  - Hang Li
year: '2023'
venue: 'arXiv preprint arXiv:2308.05374'
url: 'https://arxiv.org/abs/2308.05374'
visibility: public
check_log:
  checked_at: '2025-12-30T15:40:02.131Z'
  checked_with: 'auto:openalex'
  status: mismatch
  paper_id: 'https://openalex.org/W4385774833'
  fields:
    title:
      local: >-
        Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language
        Models' Alignment
      remote: >-
        Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language
        Models' Alignment
      match: true
    year:
      local: '2023'
      remote: '2023'
      match: true
    venue:
      local: 'arXiv preprint arXiv:2308.05374'
      remote: arXiv (Cornell University)
      match: false
      edit_distance: 20
    doi:
      local: null
      remote: 10.48550/arxiv.2308.05374
      match: true
    authors:
      local_count: 9
      remote_count: 8
      count_match: false
      details:
        - index: 0
          local: Yang Liu
          remote: Yang Liu
          first_match: true
          last_match: true
        - index: 1
          local: Yuanshun Yao
          remote: Yuanshun Yao
          first_match: true
          last_match: true
        - index: 2
          local: Jean-Francois Ton
          remote: Jean-François Ton
          first_match: true
          last_match: true
        - index: 3
          local: Xiaoying Zhang
          remote: Xiaoying Zhang
          first_match: true
          last_match: true
        - index: 4
          local: Ruocheng Guo
          remote: Ruocheng Guo Hao Cheng
          first_match: false
          last_match: false
        - index: 5
          local: Hao Cheng
          remote: Yegor Klochkov
          first_match: false
          last_match: false
        - index: 6
          local: Yegor Klochkov
          remote: Muhammad Faaiz Taufiq
          first_match: false
          last_match: false
        - index: 7
          local: Muhammad Faaiz Taufiq
          remote: Hang Li
          first_match: false
          last_match: false
  remote:
    title: >-
      Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language
      Models' Alignment
    authors:
      - Yang Liu
      - Yuanshun Yao
      - Jean-François Ton
      - Xiaoying Zhang
      - Ruocheng Guo Hao Cheng
      - Yegor Klochkov
      - Muhammad Faaiz Taufiq
      - Hang Li
    year: 2023
    venue: arXiv (Cornell University)
    doi: 10.48550/arxiv.2308.05374
tags:
  - ai-safety
  - ml-methods
  - language-models
  - 'format:survey'
cited_in:
  - data-leverage-blogs
  - personal-website
---

