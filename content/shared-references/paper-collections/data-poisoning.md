---
type: paper_collection
title: Data Poisoning & Adversarial Training
slug: data-poisoning
visibility: public
include_tags:
  - collection:data-poisoning
sort_by: year
description: >
  Research on data poisoning attacks and defenses. Covers backdoor attacks,
  training data manipulation, and adversarial robustness through the lens
  of data integrity.
tags:
  - ai-safety
  - adversarial
  - ml-methods
  - training-dynamics
---

Poisoning asks: what if someone deliberately corrupts training data? This expands the grid dramaticallyâ€”every possible perturbation creates new rows. BadNets showed how small triggers in images cause targeted misclassifications. Recent work looks at poisoning web-scale datasets and deceptive model behavior.
