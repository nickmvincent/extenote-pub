---
type: paper_collection
title: Privacy, Memorization & Unlearning
slug: privacy-memorization
visibility: public
include_tags:
  - collection:privacy-memorization
sort_by: year
description: >
  Research on privacy risks from model memorization and differential privacy
  defenses. Covers training data extraction attacks, membership inference,
  and techniques for limiting individual data point influence.
tags:
  - ai-safety
  - ml-methods
  - data-governance
  - training-dynamics
---

Models can memorize training dataâ€”sometimes enough to extract it verbatim. Differential privacy limits how much any single point can affect the model (constraining movement in the grid). The Carlini et al. extraction paper is a good entry point for understanding what's at stake.
